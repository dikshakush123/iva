{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WQ3BhIV7BiVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2OzcldbBBkHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G9RZt2jbBkKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ANk8uk6mBkNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OI2iZu5OBkQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pyMAFlZqBkSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MdoipbrjBkVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "of29VSSCBkX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8uDNdATVBkap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gEuCtxfqBkdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sd0n6uPpBkgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z1g-a53LBki0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d-PDJR85Bklh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qSY64NtwBkoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pwzdKf_JBkq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Jqp73JDBktx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TVFqK8mvBkws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6rxoLqQBBkz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3VhSeL_KBk2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4gIjGZKTBk5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1aMnpbQOBk8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ck2BoE6JBk_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2QsWTkc8BlCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d_YNQRfaBlE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gcqjnJTzBlHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BcNxUrjCBlLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rMHV3gIXBmr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NzvIX0F9BmxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IXB-yq8oBmyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0VVaVLD1Bm0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mAI8D7WRBm29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LUSoktEiBm6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "skiazImmBm8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kBUFa2LRBm_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8AxH3F_wBnCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d-zpFKDLBnF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oprdIU62Bqu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2K3HbTztBq2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DOiUxGvQBq3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q992wMaXBq42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bAapqs3kBq6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oSeUe3ISBrAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xU1V0rFNBsEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TF3lJGjCBsKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4_HrvIwUBsMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PBjEuvk8BsNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NLOw1HRGBsQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Resizing images and checking data types of Images"
      ],
      "metadata": {
        "id": "fbwWln4I5HhW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1I8efGO0zEm"
      },
      "outputs": [],
      "source": [
        "# Practical 03 : Resizing Images and checking data types of Images\n",
        "# Display The Image\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Path to your image file\n",
        "image_path = '/content/review-banner-03.jpg'\n",
        "\n",
        "img = cv2.imread(image_path)\n",
        "print('Original Image')\n",
        "cv2_imshow(img)\n",
        "height , widht = img.shape[:2]\n",
        "print(f'height * widht = {height} x {widht}')\n",
        "print('resizing into small image')\n",
        "\n",
        "\n",
        "# Resize the image  (small size)\n",
        "new_width = int(img.shape[1] * 0.5)\n",
        "new_height = int(img.shape[0] * 0.5)\n",
        "resized_img = cv2.resize(img, (new_width, new_height))\n",
        "cv2_imshow(resized_img)\n",
        "height , widht = resized_img.shape[:2]\n",
        "print(f'height * widht = {height} x {widht}')\n",
        "\n",
        "image_dataType = img.dtype\n",
        "print(image_dataType)\n",
        "\n",
        "\n",
        "\n",
        "# Resize the image (larger size)\n",
        "new_width1 = int(img.shape[1] * 2)\n",
        "new_height2 = int(img.shape[0] * 2)\n",
        "resized_img2 = cv2.resize(img, (new_width1, new_height2))\n",
        "cv2_imshow(resized_img2)\n",
        "height , widht = resized_img2.shape[:2]\n",
        "print(f'height * widht = {height} x {widht}')\n",
        "\n",
        "image_dataType = img.dtype\n",
        "print(image_dataType)\n",
        "\n",
        "\n",
        "\n",
        "######################### Converting Image into Gray Scale and then Resizing images\n",
        "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "print(gray_img)\n",
        "cv2_imshow(gray_img)\n",
        "\n",
        "\n",
        "print('resizing into small image')\n",
        "# Resize the image  (small size)\n",
        "new_width = int(gray_img.shape[1] * 0.5)\n",
        "new_height = int(gray_img.shape[0] * 0.5)\n",
        "resized_img = cv2.resize(gray_img, (new_width, new_height))\n",
        "cv2_imshow(resized_img)\n",
        "\n",
        "height , widht = resized_img.shape[:2]\n",
        "print(f'height * widht = {height} x {widht}')\n",
        "\n",
        "image_dataType = gray_img.dtype\n",
        "print(image_dataType)\n",
        "\n",
        "\n",
        "\n",
        "# Resize the image (larger size)\n",
        "new_width1 = int(gray_img.shape[1] * 2)\n",
        "new_height2 = int(gray_img.shape[0] * 2)\n",
        "resized_img2 = cv2.resize(gray_img, (new_width1, new_height2))\n",
        "cv2_imshow(resized_img2)\n",
        "height , widht = resized_img2.shape[:2]\n",
        "print(f'height * widht = {height} x {widht}')\n",
        "\n",
        "image_dataType = gray_img.dtype\n",
        "print(image_dataType)\n",
        "\n",
        "\n",
        "\n",
        "########################### Using Simple thersholding Method (to Binary Image)\n",
        "# Threshold the grayscale image to create a binary image\n",
        "# Using a simple thresholding method\n",
        "_, binary_img = cv2.threshold(gray_img, 128, 255, cv2.THRESH_BINARY)\n",
        "print(binary_img)\n",
        "cv2_imshow(binary_img)\n",
        "\n",
        "print('resizing into small image')\n",
        "# Resize the image  (small size)\n",
        "new_width = int(binary_img.shape[1] * 0.5)\n",
        "new_height = int(binary_img.shape[0] * 0.5)\n",
        "resized_img = cv2.resize(binary_img, (new_width, new_height))\n",
        "cv2_imshow(resized_img)\n",
        "height , widht = resized_img.shape[:2]\n",
        "print(f'height * widht = {height} x {widht}')\n",
        "\n",
        "image_dataType = binary_img.dtype\n",
        "print(image_dataType)\n",
        "\n",
        "\n",
        "\n",
        "# Resize the image (larger size)\n",
        "new_width1 = int(binary_img.shape[1] * 2)\n",
        "new_height2 = int(binary_img.shape[0] * 2)\n",
        "resized_img2 = cv2.resize(binary_img, (new_width1, new_height2))\n",
        "cv2_imshow(resized_img2)\n",
        "height , widht = resized_img2.shape[:2]\n",
        "print(f'height * widht = {height} x {widht}')\n",
        "\n",
        "image_dataType = binary_img.dtype\n",
        "print(image_dataType)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Basic Geometric Operations using OpenCV"
      ],
      "metadata": {
        "id": "GPZU_QQE56bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "# Display The Image\n",
        "\n",
        "# Path to your image file\n",
        "image_path = '/content/sunset-1373171_1280.jpg'\n",
        "\n",
        "img = cv2.imread(image_path)\n",
        "# Use only the thresholded image from the output of cv2.threshold\n",
        "_, img2 = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "\n",
        "\n",
        "# 4. Draw line.\n",
        "cv2.line(img2, (0, 0), (100, 100), (255, 0, 0), 5)\n",
        "\n",
        "# 5. Draw Arrowed Line.\n",
        "cv2.arrowedLine(img2, (0, 100), (100, 0), (0, 255, 0), 5)\n",
        "\n",
        "# 6. Draw Rectangle.\n",
        "cv2.rectangle(img2, (0, 100), (100, 200), (0, 0, 255), 5)\n",
        "\n",
        "# 7. Draw Circle.\n",
        "cv2.circle(img2, (50, 50), 20, (255, 255, 0), 5)\n",
        "\n",
        "# 8. Draw text on the image.\n",
        "cv2.putText(img2, 'Hello World', (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "# Display the image\n",
        "cv2_imshow(img2)"
      ],
      "metadata": {
        "id": "-i0MsxY16Dcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. To Apply Enhancement Techniques"
      ],
      "metadata": {
        "id": "4FcRJyOc6Fet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Practical 05 :- To Apply Image Enhancement Techniques\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Path to your image file (ensure the image is located at this path)\n",
        "image_path = '/content/review-banner-03.jpg'\n",
        "\n",
        "# Load the image in color\n",
        "color_img = cv2.imread(image_path)\n",
        "\n",
        "# Check if the image was loaded correctly\n",
        "if color_img is None:\n",
        "    raise FileNotFoundError(\"The image file was not loaded correctly. Please check the file path.\")\n",
        "\n",
        "# Convert the color image to grayscale\n",
        "gray_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Create an all-black image with the same dimensions as the color image\n",
        "black_img = np.zeros_like(color_img)\n",
        "\n",
        "# Display the original color, grayscale, and black images\n",
        "print(\"Original Color Image:\")\n",
        "cv2_imshow(color_img)\n",
        "print(\"Original Grayscale Image:\")\n",
        "cv2_imshow(gray_img)\n",
        "print(\"All Black Image:\")\n",
        "cv2_imshow(black_img)\n",
        "\n",
        "# Adjust brightness and contrast\n",
        "def adjust_brightness_contrast(img, brightness=0, contrast=0):\n",
        "    img = np.int16(img)\n",
        "    img = img * (contrast / 127 + 1) - contrast + brightness\n",
        "    img = np.clip(img, 0, 255)\n",
        "    img = np.uint8(img)\n",
        "    return img\n",
        "\n",
        "brightness = 30\n",
        "contrast = 50\n",
        "\n",
        "adjusted_color_img = adjust_brightness_contrast(color_img, brightness, contrast)\n",
        "adjusted_gray_img = adjust_brightness_contrast(gray_img, brightness, contrast)\n",
        "adjusted_black_img = adjust_brightness_contrast(black_img, brightness, contrast)\n",
        "\n",
        "# Display adjusted images\n",
        "print(\"Adjusted Color Image:\")\n",
        "cv2_imshow(adjusted_color_img)\n",
        "print(\"Adjusted Grayscale Image:\")\n",
        "cv2_imshow(adjusted_gray_img)\n",
        "print(\"Adjusted Black Image:\")\n",
        "cv2_imshow(adjusted_black_img)\n",
        "\n",
        "# Find digital negative of the image\n",
        "negative_color_img = 255 - adjusted_color_img\n",
        "negative_gray_img = 255 - adjusted_gray_img\n",
        "negative_black_img = 255 - adjusted_black_img\n",
        "\n",
        "# Display digital negative images\n",
        "print(\"Color Digital Negative Image:\")\n",
        "cv2_imshow(negative_color_img)\n",
        "print(\"Grayscale Digital Negative Image:\")\n",
        "cv2_imshow(negative_gray_img)\n",
        "print(\"Black Digital Negative Image:\")\n",
        "cv2_imshow(negative_black_img)\n",
        "\n",
        "# Get the red, green, and blue values of each pixel\n",
        "print(\"RGB values of the first 10x10 pixels of the negative color image:\")\n",
        "for y in range(10):\n",
        "    for x in range(10):\n",
        "        b, g, r = negative_color_img[y, x]\n",
        "        print(f\"Pixel at ({x},{y}): R={r}, G={g}, B={b}\")\n",
        "\n",
        "\n",
        "# Subtract each color value from 255 and save them as new color values\n",
        "# Create new pixel values for color image\n",
        "height, width, channels = negative_color_img.shape\n",
        "new_pixel_values = np.zeros_like(negative_color_img)\n",
        "\n",
        "for y in range(height):\n",
        "    for x in range(width):\n",
        "        b, g, r = negative_color_img[y, x]\n",
        "        new_b = 255 - b\n",
        "        new_g = 255 - g\n",
        "        new_r = 255 - r\n",
        "        new_pixel_values[y, x] = [new_b, new_g, new_r]\n",
        "\n",
        "# Save the new image\n",
        "output_path_new = '/content/new_pixel_values.jpg'\n",
        "cv2.imwrite(output_path_new, new_pixel_values)\n",
        "\n",
        "# Display the new image\n",
        "print(\"New Pixel Values Image:\")\n",
        "cv2_imshow(new_pixel_values)\n",
        "\n",
        "# Plot results using OpenCV\n",
        "print(\"Plotting results...\")\n",
        "cv2_imshow(color_img)\n",
        "cv2_imshow(adjusted_color_img)\n",
        "cv2_imshow(negative_color_img)\n",
        "cv2_imshow(new_pixel_values)"
      ],
      "metadata": {
        "id": "mikw-dAV6Ozz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. To perform Object/Image recognition on digital image transforms"
      ],
      "metadata": {
        "id": "heX6FRz26d3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#boundary detection\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Read the image\n",
        "image = cv2.imread('/content/insert1.jpg')\n",
        "\n",
        "# Step 2: Convert to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Step 3: Apply Gaussian Blur\n",
        "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "# Step 4: Use Canny Edge Detection\n",
        "edges = cv2.Canny(blurred, 50, 150)\n",
        "\n",
        "# Step 5: Find Contours\n",
        "contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Step 6: Draw Contours\n",
        "# Option 1: Draw contours on the original image\n",
        "contour_image = image.copy()\n",
        "cv2.drawContours(contour_image, contours, -1, (255, 255, 255), 2)\n",
        "\n",
        "# Option 2: Draw contours on a blank image\n",
        "blank_image = np.zeros_like(image)\n",
        "cv2.drawContours(blank_image, contours, -1, (255, 255, 255), 2)\n",
        "\n",
        "# Display the results\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Contours on Original Image')\n",
        "plt.imshow(cv2.cvtColor(contour_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Contours on Blank Image')\n",
        "plt.imshow(cv2.cvtColor(blank_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#To find Discrete Cosine Transform\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 2: Convert to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Step 3: Apply DCT\n",
        "dct = cv2.dct(np.float32(gray))\n",
        "\n",
        "# For better visualization, use a logarithmic scale\n",
        "dct_log = np.log(abs(dct) + 1)\n",
        "\n",
        "# Normalize the DCT image to the range [0, 255] for display\n",
        "dct_norm = cv2.normalize(dct_log, None, 0, 255, cv2.NORM_MINMAX)\n",
        "dct_norm = np.uint8(dct_norm)\n",
        "\n",
        "# Display the results\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Original Grayscale Image')\n",
        "plt.imshow(gray, cmap='gray')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('DCT of Image (Log Scale)')\n",
        "plt.imshow(dct_norm, cmap='gray')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#To use Haar transform for object detection\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load the Haar cascade classifier for face detection\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Step 2: Read the image\n",
        "image = cv2.imread('/content/main-qimg-6e0b1ab40d3a759f583f052f8ea1c212-lq.jfif')\n",
        "\n",
        "# Step 3: Convert to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Step 4: Detect faces\n",
        "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "\n",
        "# Step 5: Draw rectangles around the detected faces\n",
        "for (x, y, w, h) in faces:\n",
        "    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "\n",
        "# Display the result\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.title('Detected Faces')\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "k9lpXvmC6vgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Image Compression"
      ],
      "metadata": {
        "id": "QuA7t9iU638Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from google.colab import files\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Specify the image file path\n",
        "file_name = '/content/Cat03.tiff'     ##tiff format only\n",
        "\n",
        "# Load the image using OpenCV\n",
        "image = cv2.imread(file_name)\n",
        "\n",
        "# Save the image with lossless compression (PNG) using Pillow\n",
        "lossless_path = 'compressed_image_lossless.png'\n",
        "image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "image_pil.save(lossless_path, format='PNG', optimize=True)\n",
        "\n",
        "# Save the image with lossy compression (JPEG) using OpenCV\n",
        "lossy_path = 'compressed_image_lossy.jpg'\n",
        "cv2.imwrite(lossy_path, image, [int(cv2.IMWRITE_JPEG_QUALITY), 80])  # Adjust quality if needed\n",
        "\n",
        "# Load the saved compressed images\n",
        "image_lossless = cv2.imread(lossless_path)\n",
        "image_lossy = cv2.imread(lossy_path)\n",
        "\n",
        "# Convert BGR to RGB for plotting\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image_lossless_rgb = cv2.cvtColor(image_lossless, cv2.COLOR_BGR2RGB)\n",
        "image_lossy_rgb = cv2.cvtColor(image_lossy, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Get file sizes\n",
        "original_size = os.path.getsize(file_name) / 1024  # Size in KB\n",
        "lossless_size = os.path.getsize(lossless_path) / 1024  # Size in KB\n",
        "lossy_size = os.path.getsize(lossy_path) / 1024  # Size in KB\n",
        "\n",
        "# Get pixel dimensions\n",
        "height, width, channels = image.shape\n",
        "dimensions = f\"{width} x {height}\"\n",
        "\n",
        "# Get bit depth\n",
        "bit_depth = image.dtype\n",
        "\n",
        "# Calculate PSNR (Peak Signal-to-Noise Ratio) for quality comparison\n",
        "def calculate_psnr(original, compressed):\n",
        "    mse = np.mean((original - compressed) ** 2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    max_pixel = 255.0\n",
        "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
        "    return psnr\n",
        "\n",
        "psnr_lossless = calculate_psnr(image, image_lossless)\n",
        "psnr_lossy = calculate_psnr(image, image_lossy)\n",
        "\n",
        "# Handle infinite PSNR case\n",
        "psnr_lossless_str = f'{psnr_lossless:.2f}' if psnr_lossless != float('inf') else '∞'\n",
        "psnr_lossy_str = f'{psnr_lossy:.2f}' if psnr_lossy != float('inf') else '∞'\n",
        "\n",
        "# Plot the original, lossless, and lossy images with file sizes, dimensions, and PSNR\n",
        "plt.figure(figsize=(18, 8))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title(f'Original Image\\nSize: {original_size:.2f} KB\\nDimensions: {dimensions}\\nBit Depth: {bit_depth}')\n",
        "plt.imshow(image_rgb)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title(f'Lossless Compression (PNG)\\nSize: {lossless_size:.2f} KB\\nDimensions: {dimensions}\\nPSNR: {psnr_lossless_str}')\n",
        "plt.imshow(image_lossless_rgb)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title(f'Lossy Compression (JPEG)\\nSize: {lossy_size:.2f} KB\\nDimensions: {dimensions}\\nPSNR: {psnr_lossy_str}')\n",
        "plt.imshow(image_lossy_rgb)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U2QOgwEQ7Kdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Smart survillance and tracking"
      ],
      "metadata": {
        "id": "lwEamR-48wxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import IPython.display as display\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Load the pre-trained Haar Cascade classifier for face detection\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Initialize the webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "def detect_faces():\n",
        "    while True:\n",
        "        # Capture frame-by-frame\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            print(\"Failed to grab frame\")\n",
        "            break\n",
        "\n",
        "        # Convert the frame to grayscale\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Detect faces in the grayscale image\n",
        "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "        # Draw rectangles around the faces\n",
        "        for (x, y, w, h) in faces:\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "\n",
        "        # Convert frame to RGB for display\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Display the image\n",
        "        display_image(frame_rgb)\n",
        "\n",
        "        # Break the loop if 'q' is pressed\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    # Release the capture and close all OpenCV windows\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "def display_image(image):\n",
        "    \"\"\"Displays the image in Jupyter Notebook.\"\"\"\n",
        "    # Convert image to PIL format\n",
        "    pil_image = Image.fromarray(image)\n",
        "\n",
        "    # Convert PIL image to BytesIO object\n",
        "    buf = BytesIO()\n",
        "    pil_image.save(buf, format='PNG')\n",
        "\n",
        "    # Display image\n",
        "    display.display(display.Image(data=buf.getvalue()))\n",
        "    clear_output(wait=True)\n",
        "\n",
        "# Call the function to start face detection\n",
        "detect_faces()\n",
        "\n",
        "\n",
        "# In[6]:\n",
        "\n",
        "\n",
        "get_ipython().system('pip install opencv-python numpy')\n",
        "\n",
        "\n",
        "# In[7]:\n",
        "\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "print(\"OpenCV version:\", cv2.__version__)\n",
        "print(\"NumPy version:\", np.__version__)"
      ],
      "metadata": {
        "id": "RZewYlmy8z5P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}